<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Critical points and approximation</title>
    <meta charset="utf-8" />
    <meta name="author" content="MACS 33000   University of Chicago" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/lucy-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Critical points and approximation
### <a href="https://github.com/math-camp/course">MACS 33000</a> <br /> University of Chicago

---







# Learning objectives

* Define critical points
* Calculate critical points via analytical methods
* Demonstrate optimization using maximum likelihood estimation
* Identify need for approximation methods for calculating critical points
* Explain and demonstrate root finding procedures using Newton-Raphson hill climber
* Demonstrate comptuational optimization using gradient descent

---

# Rolle's theorem

* Suppose `\(f:[a, b] \rightarrow \Re\)`
* Suppose `\(f\)` has a relative maxima or minima on `\((a,b)\)` and call that `\(c \in (a, b)\)`
* Then `\(f'(c) = 0\)`

--

.pull-left[

&lt;img src="04-critical-points_files/figure-html/rolles-theorem-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

.pull-right[

* Rolle's theorem guarantee's that, at some point, `\(f^{'}(x) = 0\)`
* Intuition from proof - what happens as we approach from the left? 
* Intuition from proof - what happens as we approach from the right? 

]

---

# Higher order derivatives

* Derivatives of derivatives
* First derivative

    `$$f'(x),  ~~ y',  ~~ \frac{d}{dx}f(x), ~~ \frac{dy}{dx}$$`

* Second derivative

    `$$f''(x), ~~ y'', ~~ \frac{d^2}{dx^2}f(x), ~~ \frac{d^2y}{dx^2}$$`

* `\(n\)`th derivative

    `$$\frac{d^n}{dx^n}f(x), \quad \frac{d^ny}{dx^n}$$`

---

# Higher order derivatives

$$
`\begin{aligned}
f(x) &amp;=x^3\\
f^{\prime}(x) &amp;=3x^2\\
f^{\prime\prime}(x) &amp;=6x \\
f^{\prime\prime\prime}(x) &amp;=6\\
f^{\prime\prime\prime\prime}(x) &amp;=0\\
\end{aligned}`
$$

* If `\(f(x)\)` is differentiable, also continuous
* If `\(f'(x)\)` is differentiable, then **continuously differentiable**
* Optimization requires differentiation

---

# Inflection point

&gt; For a given function `\(y = f(x)\)`, a point `\((x^∗, y^∗)\)` where the second derivative immediately on one side of the point is signed oppositely to the second derivative immediately on the other side

&lt;img src="04-critical-points_files/figure-html/inflect-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Concavity

* Chord
* Concave up (convex)
* Concave down (concave)
* Verification
    * Graphically
    * Analytically

---

# Concavity

* Where a function is twice differentiable and concave over some area, then the function is concave down where `\(f''(x) &lt; 0\)` and concave up where `\(f''(x) &gt; 0\)`

&lt;img src="04-critical-points_files/figure-html/concave-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Exponential function

.pull-left[

&lt;img src="04-critical-points_files/figure-html/strict-e-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

.pull-right[

$$
`\begin{aligned}
f(x) &amp; =  e^{x} \\
f^{'}(x) &amp; =  e^{x} \\
f^{''}(x) &amp; =  e^{x} 
\end{aligned}`
$$

]

---

# Natural logarithm


.pull-left[

&lt;img src="04-critical-points_files/figure-html/strict-log-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

.pull-right[

$$
`\begin{aligned}
f(x) &amp; =  \log(x) \\
f^{'}(x) &amp; =  \frac{1}{x} \\
f^{''}(x) &amp; =  -\frac{1}{x^2}
\end{aligned}`
$$

]

---

# Types of extreme values

* Maximum or minimum
* Local or global

---

# Types of extreme values

&lt;img src="04-critical-points_files/figure-html/endpoints-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Types of extreme values

&lt;img src="04-critical-points_files/figure-html/max-middle-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Types of extreme values

&lt;img src="04-critical-points_files/figure-html/min-middle-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Types of extreme values

&lt;img src="04-critical-points_files/figure-html/local-all-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Types of extreme values

&lt;img src="04-critical-points_files/figure-html/inflection-point-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Framework for analytical optimization

1. Find `\(f'(x)\)`
1. Set `\(f'(x)=0\)` and solve for `\(x\)`. Call all `\(x_0\)` such that `\(f'(x_0)=0\)` **critical values**
1. Find `\(f''(x)\)`. Evaluate at each `\(x_0\)`
    * If `\(f''(x) &gt; 0\)`, concave up, and therefore a local minimum
    * If `\(f''(x) &lt; 0\)`, concave down, and therefore a local maximum
    * If it's the global maximum/minimum, it will produce the largest/smallest value for `\(f(x)\)`
    * On a closed range along the domain, check the endpoints as well

---

# `\(f(x) = -x^2\)`,  `\(x \in [-3, 3]\)`

&lt;img src="04-critical-points_files/figure-html/ex-1-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# `\(f(x) = x^3\)`, `\(x \in [-3, 3]\)`

&lt;img src="04-critical-points_files/figure-html/ex-2-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Maximum likelihood estimation

* Likelihood function
* Distinguish from probability
* Known data, unknown parameters
* Maximize to find the values located at the **global maximum** of the likelihood function

---

# Maximum likelihood estimation

$$
`\begin{aligned}
f(\mu) &amp; = \prod_{i=1}^{N} \exp( \frac{-(Y_{i} - \mu)^2}{ 2}) \\
&amp; = \exp(- \frac{(Y_{1} - \mu)^2}{ 2}) \times \ldots \times \exp(- \frac{(Y_{N} - \mu)^2}{ 2}) \\
&amp; = \exp( - \frac{\sum_{i=1}^{N} (Y_{i} - \mu)^2} {2})
\end{aligned}`
$$

* Maximizing a function with very very very small numbers

---

# Maximum likelihood estimation

* Log-likelihood
    * `\(f:\Re \rightarrow (0, \infty)\)`
    * If `\(x_{0}\)` maximizes `\(f\)`, then `\(x_{0}\)` maximizes `\(\log(f(x))\)`
* Maximize the log-likelihood instead

---

# Maximum likelihood estimation

$$
`\begin{aligned}
\log f(\mu) &amp; = \log \left( \exp( - \frac{\sum_{i=1}^{N} (Y_{i} - \mu)^2} {2}) \right)  \\
&amp; = - \frac{\sum_{i=1}^{N} (Y_{i} - \mu)^2} {2} \\
	&amp; = -\frac{1}{2} \left(\sum_{i=1}^{N} Y_{i}^2 - 2\mu \sum_{i=1}^{N} Y_{i} + N\times\mu^2 \right) \\
\frac{ \partial \log f(\mu) }{ \partial \mu } &amp; = 		-\frac{1}{2} \left( - 2\sum_{i=1}^{N} Y_{i} + 2 N \mu \right) 
\end{aligned}`
$$

---

# Maximum likelihood estimation

$$
`\begin{aligned}
0 &amp; = -\frac{1}{2} \left( - 2 \sum_{i=1}^{N} Y_{i} + 2 N \mu^{*} \right) \\
0 &amp; = \sum_{i=1}^{N} Y_{i} - N \mu^{*}  \\
N \mu^{*}  &amp; =  \sum_{i=1}^{N}Y_{i} \\
\mu^{*} &amp; = \frac{\sum_{i=1}^{N}Y_{i}}{N} \\
\mu^{*} &amp; = \bar{Y}
\end{aligned}`
$$

---

# Maximum likelihood estimation

* Second derivative test

$$
`\begin{aligned}
f^{'}(\mu ) &amp; = -\frac{1}{2} \left( - 2\sum_{i=1}^{N} Y_{i} + 2 N \mu \right) \\
f^{'}(\mu ) &amp; = \sum_{i=1}^{N} Y_{i} - N \mu \\
f^{''}(\mu ) &amp; = -N 
\end{aligned}`
$$

--

* `\(-N&lt;0 \leadsto \text{concave down}\)`

---

# Computational optimization procedures

* Analytical approaches can be difficult/impossible
* Computational approaches simplify the problem
* Different algorithms available with benefits/drawbacks
    * Newton-Raphson
    * Grid search
    * Gradient descent

---

# Newton-Raphson root finding

* Roots of a function where `\(f(x) = 0\)`
* Analytical method
* Iterative procedures to approximate `\(x^{*}\)`

---

# Tangent lines

`$$g(x) = f^{'}(x_{0}) (x - x_{0} ) + f(x_{0})$$`

&lt;img src="04-critical-points_files/figure-html/tangent-anim-1.gif" style="display: block; margin: auto;" /&gt;

---

# Newton-Raphson method

* Initial guess `\(x_{0}\)`
* Approximate `\(f(x)\)` with the tangent line to generate a new guess:

    `$$\begin{aligned}g(x) &amp; = f^{'}(x_{0})(x - x_{0} ) + f(x_{0} ) \\0 &amp; = f^{'}(x_{0}) (x_{1} - x_{0}) + f(x_{0} ) \\x_{1} &amp; =  x_{0} - \frac{f(x_{0}) }{f^{'}(x_{0})}\end{aligned}$$`

* Iterate until updated values are the same

---

# Example of Newton-Raphson

.pull-left[

&lt;img src="04-critical-points_files/figure-html/base-plot-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

.pull-right[

$$
`\begin{aligned}
y &amp;= -x^2 \\
\frac{\partial y}{\partial x} &amp;= -2x \\
\frac{\partial^2 y}{\partial x^2} &amp;= -2
\end{aligned}`
$$

]

---

# Example of Newton-Raphson

.pull-left[

&lt;img src="04-critical-points_files/figure-html/optims-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

.pull-right[

$$
`\begin{aligned}
y &amp;= -x^2 \\
\frac{\partial y}{\partial x} &amp;= -2x \\
\frac{\partial^2 y}{\partial x^2} &amp;= -2
\end{aligned}`
$$

]


---

# Implementing Newton-Raphson

`$$x_1 = x_0 - \frac{f'(x_0)}{f''(x_0)}$$`

--

`$$x_{n+1} = x_n - \frac{f'(x_n)}{f''(x_n)}$$`

--

`$$x_{n+1} = x_n - \frac{-2x}{-2}$$`

* Stop at `\(x_n\)` if `\(\mid x_n - x_{n-1} \mid &lt; 0.0001\)`

---

# Implementing Newton-Raphson





&lt;img src="04-critical-points_files/figure-html/first-func-first-guess-1.gif" style="display: block; margin: auto;" /&gt;

---

# Implementing Newton-Raphson

.pull-left[

&lt;img src="04-critical-points_files/figure-html/base-plot-two-points-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

.pull-right[

$$
`\begin{aligned}
y &amp;= x^3 + 2x^2 - 3x + 4 \\
\frac{\partial y}{\partial x} &amp;=  3x^2 + 4x - 3 \\
\frac{\partial^2 y}{\partial x^2} &amp;= 6x + 4
\end{aligned}`
$$

]

---

# Implementing Newton-Raphson

.pull-left[

&lt;img src="04-critical-points_files/figure-html/optims-two-points-1.png" width="432" style="display: block; margin: auto;" /&gt;

]

.pull-right[

$$
`\begin{aligned}
y &amp;= x^3 + 2x^2 - 3x + 4 \\
\frac{\partial y}{\partial x} &amp;=  3x^2 + 4x - 3 \\
\frac{\partial^2 y}{\partial x^2} &amp;= 6x + 4
\end{aligned}`
$$

]

---

# Initial guess `\(x_0 = 10\)`



&lt;img src="04-critical-points_files/figure-html/second-func-first-guess-1.gif" style="display: block; margin: auto;" /&gt;

---

# Initial guess `\(x_0 = -10\)`

&lt;img src="04-critical-points_files/figure-html/second-func-second-guess-1.gif" style="display: block; margin: auto;" /&gt;

---

# Grid search

* Exhaustive search algorithm
* Define a specified set of `\(f_i\)`
* Calculate `\(f(x_i) \forall i\)`
* Compare all resulting values

---

# Grid search

`$$y = -x^2$$`

* Evaluate the function for all `\(x \in \{ -2, -1.99, -1.98, \ldots, 1.98, 1.99, 2 \}\)`

--

&lt;img src="04-critical-points_files/figure-html/grid-search-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Gradient descent

&lt;img src="04-critical-points_files/figure-html/grad-ex-1.png" width="864" style="display: block; margin: auto;" /&gt;

---

# Analytically optimize

$$
`\begin{aligned}
f'(x) &amp;= 2.4x - 4.8 \\
0 &amp;= 2.4x - 4.8 \\
4.8 &amp;= 2.4x \\
x &amp;= 2
\end{aligned}`
$$

--

$$
`\begin{aligned}
f''(x) &amp;= 2.4 \\
f''(2) &amp;= 2.4
\end{aligned}`
$$

---

# Gradient descent

`$$x_1 = x_0 - \alpha f'(x_0)$$`

* Gradient
* Learning rate
* Iterative algorithm
* Important components

---

# `\(\alpha = 0.6\)`





&lt;img src="04-critical-points_files/figure-html/grad-descent-learn-rate-6-1.gif" style="display: block; margin: auto;" /&gt;

---

# `\(\alpha = 0.1\)`

&lt;img src="04-critical-points_files/figure-html/grad-descent-learn-rate-2-1.gif" style="display: block; margin: auto;" /&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://cfss.uchicago.edu/slides/macros.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script src="https://www.redditstatic.com/comment-embed.js"></script>
<script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
